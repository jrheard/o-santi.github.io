#+TITLE: Rust Engineering Lead
#+AUTHOR: Leonardo Ribeiro Santiago (120036072)
#+OPTIONS: toc:nil date:nil
#+LATEX_HEADER: \usepackage[portuguese]{babel}

* Engineering experience
** Describe a skill or knowledge you acquired recently that has been impactful for you. Why did you make this investment? What has the outcome been?
I've been investing the last year to learning NixOS, and nix systems (especially flakes) in general, and it honestly has paid off so much. As everyone says, it's a technology with a very steep learning curve, as the documentation is sparse and most of the times outdated, and to get up to date info you almost always need to look at the source code.

Still, nixpgks is amazing and been able to provide me with never breaking software and fearless upgrades, so that I can confidently keep my machines up to date. Nowadays I use it both in my main machine and in my laptop, using different configs derived from the same flake (sharing almost everything).

** What new skill would you like to learn? Why do you think this is important or timely or interesting? Why do you think you will be good at it?

NixOS got me very interested in the DevOps field, as I find it very good at managing multiple computers' configurations and setups. I also think I'm a good fit for that side of programming, as it usually requires a very rich understanding of linux, as well as integration between different systems.

** What kinds of software projects have you worked on before? Which operating systems, development environments, languages, databases?

Professionally, I daily deal with Python, Rust, PostgreSQL and Nix (and NixOS). In the past I've also worked in other languages, such as Haskell, a fair bit of Javascript, LaTex and XML, and C. For some smaller projects I've interacted with OCaml (built my old blog generator from scratch on it), Coq and Lean (proof assistants), common-lisp (for the NES emulator) and emacs lisp (daily). As far as operating systems go, I've started on WSL, then quickly hopped on Ubuntu, had some graphics card drivers issues, hopped to Arch linux, also had driver issues, hopped on to Manjaro, suffered from the same issues, then back to windows for a while where my laptop worked. Last year I decided to go full time on NixOS, and I've been happily using it ever since.

** Why Rust? What is your history with this language?

My history in Rust is very tangled with my history with functional languages in general. I have a very non-standard history, in that I learned functional programming through a friend, while trying to implement a more powerful parser at my first (junior) job. He explained to me about parser combinators and introduced me to the language he was working on, called Kind. I loved programming in Kind, as it's syntax was very much javascript like (on purpose) but it was dependently typed (used a very simple non-standard theory called self-types). I tried writing a parser to fit for my needs at the time, but I was clearly not knowledgeable enough (and looking back what I was trying to acchieve wasn't even possible).

Curiously enough, two years later I went to the same company that my friend was working on, and they were using Rust (to build a functional runtime). I had heard it about it by then, and certainly knew a thing or two, but had no experience in it professionally so getting to work with it gave me the same feeling as I had with Kind. It was a very powerful language, with very high performance (which Kind didn't have), and a strict compiler that does not take a whole minute to verify? Neat! I loved it, and started quickly munching through every piece of rust info I could find on the internet: blogs, conference talks (I love seeing those), tutorials, etc. I then learned about how the borrow checker works, why it works, and got even more in love with it, and still to this day I try writing everything I can on it.

The thing that always makes me motivated to work around Rust is the fact that it makes it possible to make invalid states unrepresentable (which is the whole point of correctness). The prime example to this is the way errors are handled in Go: you return a tuple, with a good value and an error value, and you *must* only set only one of them, while the other is null. This begs for the obvious question: what happens when you set both of them? Most of the time, this leads to undefined behaviour, because often it will rely on the assumption that only one of them is set in the code, but Go *has no way of ensuring that*. Rust on the other hand handles this gracefully by using type variants, so that instead of a tuple containing both, it can be statically asserted that it always returns one of the kind.

** Would you describe yourself as a high quality coder? Why?

I think the main quality any serious developer should value the most is correctness, in so far as accurately describing your problem, then accurately describing your algorithm (and how it *always* solve your problem, not /mostly/ or /generally/, *always*), then finally making sure that the code you write implements the algorithm faithfully (possibly making use of proof assistants to verify certain key pro. If code is done this way, thoroughly and paying due diligence, then the resulting product will always be of the highest quality, without a doubt. And I'm a programmer who always strive for doing this process, which makes me a high quality coder.

Of course, it isn't possible to always strictly adhere to this schedule, be it because of tight business schedules, or maybe your project's ambitions are just too broad to accurately describe every facet in a humans' life span, but I still think that following as much as you can will still get you to a high quality product in the end.

** Outline your thoughts on open source software development. What is important to get right in open source projects? What open source projects have you worked on? Have you been an open source maintainer, on which projects, and what was your role?

I value very much open source software, and I try as much as possible to keep my personal projects open source. My NixOS config is the best example, where I openly strived to make it open source, even though I had to keep personal secrets in it. Due to this, I went through a lengthy span of time searching for possible solutions and finally arrived at the current one I use (agenix, where the secrets are encrypted with my systems public ssh keys, and having one private key is enough to decrypt them), and I will always happily share it with everyone, as open source is probably the main reason I know everything that I know today.

The main thing to get correctly right in open source projects is to have a clear, specified goal that it tries to solve, in order to make it possible to probe whether or not it is in the right direction (which incidentally aligns very well with the Unix philosophy). I believe this to be necessary because projects with very broad ambitions tend to either get everything done in a half baked way or simply to ditch some parts in favor of others, or just to be abandoned altogether due to the sheer complexity. This is further supported by the fact that there are very few everlasting monolythical open source projects, with emacs and the linux kernel being the only ones that come to mind (and both of them have very clear flaws, though I'm much more knowledgeable in emacs). Most successful projects tend then to be done in layers developed separately with different goals, with the best example being the very-common-in-linux hierarchy: kernel -> OS -> window servers -> window managers -> applications, and still composing is a common source of problems (X11 vs wayland).

Personally, I have contributed to a few open source projects that are not my own, with the biggest one that comes to mind being [[https://github.com/o-santi/nocargo][nocargo]], a rust build tool intended to supersede cargo inside nix, written entirely in nix. It has solves some very clear problems that cargo can't really tackle (while being a rust build tool), like crate level caching (which is the best you can do with rustc, as crates are it's unit of compilation) that are globally shared through different projects, and probably the most important one being clearly expressing dependencies on non-rust software. My role was mostly to extend it's features, because it remained unmantained for almost 2 years, in order to support new cargo features that were breaking compatibility otherwise. Though I got it to a good state (where I use it daily with no problems), I haven't had time to properly merge it to the main branch (neither has oxalica) so it remains an open [[https://github.com/oxalica/nocargo/pull/17][pull request]] to this day. I still intend to finish it once I have more free time.

** Describe your experience building large systems with many services - web front ends, REST APIs, data stores, event processing and other kinds of integration between components. What are the key things to think about in regard to architecture, maintainability, and reliability in these large systems?

Working with large systems with many services is my main job at Mixrank. We have a lot of public API's, dozens of databases, client deliveries schemes and most importantly, in-house tooling to dealing with all of the requirements (some of which are open source).

I believe there are three key facets to think about when building this kind of software, which are clear structure, static checkers (be it compiler, linter or other kind of tools) and good documentation. They are needed to solve the most common source of problems in big systems: the overwhelmingly big context you need to hold in your mind in order to make any simple change.
- Good project structure makes it so that all of your changes are local (they won't break other parts elsewhere) and that you don't need to keep track of multiple places to update (eg. having to update the same address in 7 separate parts of the codebase).
- Static checkers give you confidence to structure code in a way such that preventable mistakes (such as type errors or forgetable edge cases) can be seen before they get to production.
- Good documentation makes information accessible to newcomers and introduces them to the codebase, while also keeping clear what the semantics of certain parts of the code is assumed to be (eg. what does it mean when this field is null in this API call?).
  
** How comprehensive would you say your knowledge of a Linux distribution is, from the kernel up? How familiar are you with low-level system architecture, runtimes and Linux distro packaging? How have you gained this knowledge?

I'd say I'm not that confident at the kernel, since I don't have much experience working with. Though, I have built some low-level systems and runtimes (both my at my previous company and my current one), that give me confidence when interacting with the kernel. In distro packaging, I have a lot of experience in packaging software to NixOS, both because of using it daily to solve my own problems, and to solve needs for my current job. It also gives me a lot of insights into other distros packaging system too (how to do it correctly).

** Outline your thoughts on quality in software development. What practices are most effective to drive improvements in quality?

First we must define what quality is: for me, it boils down to two predicates:
1. Predictability, in so far as always doing the same thing with the same input, and having specifiable outputs on different inputs. 
2. Reliability, as in it won't break because of unexpected inputs, or strange edge cases that aren't handled well.

This kind of software quality must strictly come from strict adherence to correctness, as I've answered before. The more you formally specify semantics around your code, the more reliable and predictable it will become, and thus higher the quality. Ideally you'd like your whole software to be a single state machine, which clearly defined transitions for each state; though this isn't always feasible, mostly due to scale. Small scale software can and should be state machines with clear state trasitions - think of rust builder patterns, regexes, parsers and http requests - and composing them simply and correctly is the best way to ensure highest software quality.

** Outline your thoughts on documentation in large software projects. What practices should teams follow? What are great examples of open source docs?

I think source code will always be the best documentation. People tend to forget to update documentation (especially in lesser important parts of the project) and it can't be expected to always be updated. Since there's no way to verify that the semantics in the comments will always match the one in the code (and the code being the actual thing that we can verify), we shouldn't realy on it being up to date.

A good practice is to make documentation automatically generated from source code (and automatically updated by CI), especialely when it can then be indexed later by a searching tool, with the best examples that come to mind being [[https://hoogle.haskell.org/][hoogle]] and rust docs themselves, which optionally let you include comments for functions and type definitions. 

** Outline your thoughts on user experience, usability and design in software. How do you lead teams to deliver outstanding user experience?

Outstanding user experience always comes from reliability, and making sure that outcomes are clearly defined. Does you software expect a filepath as an input? Then, it must gracefully handle the case where the input is *not* a file path, clearly explaining to the user how to correctly use the software.

You must also have consistent behavior around your codebase: you either accept relative paths or you don't, throughout your commands/subcommands/inputs, that is, you can't tell the user you expect a certain pattern in input A and then have that same pattern fail in input B.

** Outline your thoughts on performance in software engineering. How do you ensure that your product is fast?

Performance always come from good design. There's no such thing as "implement first, optmize later" as it always lead to huge software refactors whenever performance isn't satisfactory enough. One must always predict how certain algorithms can be implemented *correctly* through the designing phase, to then try to predict whether or not the expected performance is going to be satisfactory.

Sometimes the only way to correctly handle all the inputs is through a slow and memory heavy O(n^5) algorithm. A good engineer should then consider: why is this algorithm so slow? Can I expect it to be faster? Are most cases actually O(n) and only edge cases perform worse? Maybe you can consider limiting your input to only good performing algorithms, and explain to the user that in the edge cases it won't perform so well - or maybe you can outright prohibit the user of inputting these edge cases.

** Outline your thoughts on security in software engineering. How do you lead your engineers to improve their security posture and awareness?

To increase security and awareness is to increase understanding around the codebase, mainly around the semantics. Most security mistakes comes from not handling *correctly* (the word I always mention) edge cases in your software be them:
1. unexpected inputs are not correctly handled.
2. null pointer dereference - when you assume some pointer points to valid memory when it really doesn't.
3. out of bounds memory access - when you incorrectly assert the size of the array you're reading from, most common when there are complicated loop relationships in indexes.
4. unexpected semantics in language design - think of mutable default arguments in python, that are a common source of headaches (when someone expects them to be reset every call, but in fact they're shared through multiple calls).
5. wrong ownership semantics - assuming it's fine to modify some non-local variable inside a function (that should not modify it).

A generally safe language will solve *1*, *2* and *3*, through static types, ~Option~, ~Result~, and bounds checking. A well designed language can also solve *4*. But only Rust can solve *5*, through the complicated analysis of the borrow checker. When using a language that does not solve any of these problems, we then force the programmer to keep these complicated relationships in their head, *at all times*, and it is not reasonable to assume that people won't make mistakes - even the most experienced programmer will spew out a few problems per week. Then, Rust's job on software security is clear: empower people to write correct software, and allow them to focus on actually delivering value (instead of fighting a data race condition).

Also, I don't think unit testing (or any kind of testing) significantly improve security. Of course, in dynamic languages, where static analyzers are hard to get, they are important in assuring that you are not forgeting anything, but I absolutely do not think that adding one thousand tests will solve issues. Issues happen exactly because you did not think of them and instead of adding a test to handle a specific edge case, you're much better off ensuring that your program handles *all* classes of edge cases. Ideally, you'd like to formally specify your software - with the prime example being [[https://compcert.org/man/manual001.html][CompCert]], where reportedly Csmith (a C code fuzzy tester) couldn't find any bugs in the well-verified and checked middle-end (compiler optimizations passes) that other major compilers (gcc, llvm) were infested (300+); the only bugs found in the compiler where in the non-verified front end (the C parser), measly 9 bugs.

** Outline your thoughts on DevOps and DevSecOps. Which practices are effective, and which are overrated?

Mostly I think what really makes DevOps efective is being able to *completely* reason about your system before sending them off to the production servers. Being able to describe the exact end state of the software in your system beforehand lets you ensure key properties (eg. user X must always have ssh key Y when condition Z happens).

This is exactly why I like NixOS: it's whole idea is to separate build from recipe. That is, you're able to describe and instantiate a complete recipe for a system, ranging from installed programs, to users configurations, to installed fonts, to services that must run on startup and their configurations as well, all while using a powerful turing complete language - which is great for structuring your code and making it readable and sharable.

Then, you are also able to, before installing the whole spec in the machine, inspect the end state of it inside a common repl. For example, lets say you have a list of users with roles and ssh keys, and you'd like to give each user permissions to machines based on their roles. In NixOS, this is as simple as importing the users, doing a common loop (in functional programming, a fold) and then assingning the correct value to each field of the configuration. To ensure you are correct, you're also able to instantiate, and see exactly which users have access to that machine *before installing*, and NixOS ensures you that those are the exact ones that will have access to it.

